from fastapi import APIRouter, Query
from pydantic import BaseModel
from typing import List, Optional
import random

router = APIRouter()

# === AI Tutor Models ===
class ChatMessage(BaseModel):
    role: str
    content: str

class ChatRequest(BaseModel):
    userId: int
    message: str
    topic: Optional[str] = "é€™å€‹æ¦‚å¿µ"
    mode: Optional[str] = "understanding"
    context: Optional[List[ChatMessage]] = []

class ChatResponse(BaseModel):
    response: str
    followUp: Optional[str] = None

class InterventionResponse(BaseModel):
    shouldIntervene: bool
    type: Optional[str] = None
    message: Optional[str] = None
    suggestion: Optional[str] = None
    action: Optional[dict] = None
    topic: Optional[str] = None
    subjectName: Optional[str] = None

# === Prompt Templates ===
SOCRATIC_PROMPTS = {
    "understanding": [
        "å¾ˆå¥½çš„é–‹å§‹ï¼é‚£é€™å€‹æ¦‚å¿µå’Œ{topic}çš„å…¶ä»–éƒ¨åˆ†æœ‰ä»€éº¼é—œè¯å‘¢ï¼Ÿ",
        "ä½ è§£é‡‹å¾—ä¸éŒ¯ï¼ä½†å¦‚æœæœ‰äººå•ä½ ã€Œç‚ºä»€éº¼ã€ï¼Œä½ æœƒæ€éº¼å›ç­”ï¼Ÿ",
        "æœ‰è¶£çš„è§€é»ï¼èƒ½èˆ‰ä¸€å€‹å…·é«”çš„ä¾‹å­ä¾†èªªæ˜å—ï¼Ÿ",
        "ä½ æåˆ°äº†é—œéµé»ã€‚é‚£å¦‚æœæ¢ä»¶æ”¹è®Šäº†ï¼Œçµè«–æœƒæœ‰ä»€éº¼ä¸åŒï¼Ÿ"
    ],
    "application": [
        "é€™æ˜¯å€‹å¥½çš„æ‡‰ç”¨ä¾‹å­ï¼é‚£åœ¨ç›¸åçš„æƒ…æ³ä¸‹å‘¢ï¼Ÿ",
        "ä½ æƒ³åˆ°äº†å¯¦éš›ç”¨é€”ï¼é‚£é€™å€‹æ¦‚å¿µé‚„èƒ½è§£æ±ºä»€éº¼å•é¡Œï¼Ÿ",
        "ä¸éŒ¯çš„æƒ³æ³•ï¼å¦‚æœæŠŠé€™å€‹æ‡‰ç”¨åˆ°æ›´è¤‡é›œçš„æƒ…æ³ï¼Œæœƒç™¼ç”Ÿä»€éº¼ï¼Ÿ"
    ],
    "recall": [
        "ä½ è¨˜å¾—å¾ˆå¤šï¼é‚£é€™äº›è¦é»ä¹‹é–“æœ‰ä»€éº¼é—œè¯ï¼Ÿ",
        "å¾ˆå¥½ï¼é‚„æœ‰ä»€éº¼å®¹æ˜“è¢«å¿½ç•¥ä½†å¾ˆé‡è¦çš„ç´°ç¯€ï¼Ÿ",
        "ä½ å›æ†¶å¾—ä¸éŒ¯ï¼é‚£æœ€å®¹æ˜“æ··æ·†çš„éƒ¨åˆ†æ˜¯ä»€éº¼ï¼Ÿ"
    ]
}

ENCOURAGEMENT_MESSAGES = [
    "ä½ çš„å›ç­”é¡¯ç¤ºå‡ºæ·±å…¥çš„æ€è€ƒï¼",
    "é€™å€‹è§’åº¦å¾ˆæœ‰è¦‹åœ°ï¼",
    "ä½ æ­£åœ¨å»ºç«‹å¾ˆå¥½çš„ç†è§£ï¼",
    "ç¹¼çºŒé€™æ¨£æ€è€ƒï¼Œä½ æœƒè¶Šä¾†è¶Šæ¸…æ™°ï¼"
]

@router.post("/chat", response_model=ChatResponse)
async def chat_with_tutor(request: ChatRequest):
    """
    Socratic dialogue with AI tutor
    """
    mode = request.mode or "understanding"
    topic = request.topic or "é€™å€‹æ¦‚å¿µ"
    
    # Get appropriate prompts for mode
    prompts = SOCRATIC_PROMPTS.get(mode, SOCRATIC_PROMPTS["understanding"])
    
    # Generate response based on context length (simulate deepening conversation)
    context_length = len(request.context)
    
    if context_length >= 6:
        # After 3 exchanges, provide summary
        response = f"""ğŸ¯ ç¶“éæˆ‘å€‘çš„å°è©±ï¼Œä½ å°ã€Œ{topic}ã€çš„ç†è§£å·²ç¶“æ›´æ·±å…¥äº†ï¼

ç¸½çµä¸€ä¸‹ä½ çš„é—œéµè¦‹è§£ï¼š
â€¢ ä½ èƒ½ç”¨è‡ªå·±çš„è©±è§£é‡‹æ ¸å¿ƒæ¦‚å¿µ
â€¢ ä½ èƒ½èˆ‰å‡ºå¯¦éš›æ‡‰ç”¨çš„ä¾‹å­
â€¢ ä½ æ³¨æ„åˆ°äº†å®¹æ˜“æ··æ·†çš„åœ°æ–¹

ğŸ’ª ç¹¼çºŒä¿æŒé€™ç¨®ä¸»å‹•æ€è€ƒçš„ç¿’æ…£ï¼"""
        followUp = None
    else:
        # Select random follow-up question
        encouragement = random.choice(ENCOURAGEMENT_MESSAGES)
        question = random.choice(prompts).replace("{topic}", topic)
        response = f"{encouragement}\n\n{question}"
        followUp = question
    
    return ChatResponse(response=response, followUp=followUp)


@router.get("/intervention", response_model=InterventionResponse)
async def check_intervention(userId: int = Query(1)):
    """
    Check if AI should proactively intervene
    """
    # In production, this would check:
    # - Time spent on current topic
    # - Error patterns in flashcards
    # - Session duration
    # - User's historical performance
    
    # For demo, randomly suggest interventions
    if random.random() < 0.3:  # 30% chance
        interventions = [
            {
                "type": "struggle",
                "message": "æˆ‘æ³¨æ„åˆ°ä½ åœ¨ã€Œæ¥µé™ã€é€™å€‹æ¦‚å¿µä¸ŠèŠ±äº†æ¯”è¼ƒå¤šæ™‚é–“",
                "suggestion": "è¦ä¸è¦è©¦è©¦ç”¨ Feynman æ–¹æ³•ä¾†è§£é‡‹å®ƒï¼Ÿ",
                "action": {"label": "é–‹å§‹å°è©±", "type": "chat"},
                "topic": "æ¥µé™",
                "subjectName": "å¾®ç©åˆ†"
            },
            {
                "type": "break",
                "message": "ä½ å·²ç¶“å°ˆæ³¨å­¸ç¿’ 45 åˆ†é˜äº†ï¼Œåšå¾—å¾ˆå¥½ï¼",
                "suggestion": "å»ºè­°ä¼‘æ¯ 5-10 åˆ†é˜ï¼Œè®“å¤§è…¦éå›ºè¨˜æ†¶",
                "action": {"label": "é–‹å§‹ä¼‘æ¯", "type": "break"}
            },
            {
                "type": "strategy",
                "message": "æ ¹æ“šä½ çš„å­¸ç¿’æ•¸æ“šï¼Œè©¦è©¦äº¤éŒ¯å­¸ç¿’å¯èƒ½æœƒæ›´æœ‰æ•ˆ",
                "suggestion": "åœ¨å¾®ç©åˆ†å’Œç·šæ€§ä»£æ•¸ä¹‹é–“åˆ‡æ›ï¼Œæå‡è¾¨åˆ¥èƒ½åŠ›",
                "action": {"label": "åˆ‡æ›ç§‘ç›®", "type": "switch"},
                "topic": "äº¤éŒ¯å­¸ç¿’",
                "subjectName": "å­¸ç¿’ç­–ç•¥"
            }
        ]
        
        intervention = random.choice(interventions)
        return InterventionResponse(
            shouldIntervene=True,
            **intervention
        )
    
    return InterventionResponse(shouldIntervene=False)


@router.get("/memory/{userId}")
async def get_user_memory(userId: int):
    """
    Get AI's memory of user preferences and patterns
    """
    # In production, this would retrieve from database
    return {
        "userId": userId,
        "weakConcepts": ["æ¥µé™", "Taylorå±•é–‹"],
        "strongConcepts": ["å°æ•¸åŸºæœ¬é‹ç®—", "ç©åˆ†æŠ€å·§"],
        "preferredStrategies": ["Pomodoro", "ä¸»å‹•å›æ†¶"],
        "bestStudyTimes": ["20:00-22:00"],
        "averageFocusScore": 75,
        "commonMistakes": [
            {"concept": "æ¥µé™", "pattern": "å¿½ç•¥å·¦æ¥µé™å³æ¥µé™çš„å€åˆ¥"},
            {"concept": "ç©åˆ†", "pattern": "å¿˜è¨˜åŠ å¸¸æ•¸C"}
        ],
        "recentProgress": [
            {"concept": "å°æ•¸", "improvement": "+15%"},
            {"concept": "é€£é–å¾‹", "improvement": "+8%"}
        ]
    }


@router.post("/memory/{userId}/update")
async def update_user_memory(userId: int, update: dict):
    """
    Update AI's memory with new observations
    """
    # In production, this would persist to database
    return {
        "success": True,
        "message": "Memory updated",
        "userId": userId
    }
